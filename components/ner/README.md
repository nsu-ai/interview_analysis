# Распознаватель именованных сущностей

Модуль предназначен для распознавания именованных сущностей 29 классов (полный список классов сущностей описан в [репозитории соревнования RuNNE](https://github.com/dialogue-evaluation/RuNNE/blob/main/public_data/ners.txt)). Именованные сущности могут быть вложенными, то есть одна именованная сущность является частью другой. Например, фраза "_Донецкий национальный технический университет_" является именованной сущностью класса ORGANIZATION, но подфраза "_Донецкий_" одновременно с этим является сущностью класса LOCATION.

Модуль основан на алгоритме сопоставительного обучения для распознавания именованных сущностей **CoNER**, или **Co**ntrastive **NER**, апробированного в ходе научного соревнования [RuNNE](https://www.dialog-21.ru/evaluation/2022/runne/). Решение, которое было основано на данном алгоритме, заняло третье место в общем зачёте (см. результаты команды _**SibNN**_ в таблице _Results_ на [платформе Codalab](https://codalab.lisn.upsaclay.fr/competitions/1863#results)).

## Структура

    .
    ├── data                        # Данные (примеры, необходимые маленькие файлы, инструкции по датасетам)
    │   │
    │   ├── input_example.json      # Пример входных данных
    │   └── output_example.json     # Пример выходных данных
    │
    ├── scripts                     # Служебные функции, скрипты для подготовки датанных и распознавания
    │   │
    │   │── data_processing         # Модуль для токенизации текстов, извлечения признаков, постобработки результатов распознавания и т.п.
    │   │── neural_network          # Модуль с нейросетями для NER
    │   └── download_model.py       # Скрипт загрузки обученной модели с Яндекс-диска
    │
    ├── models                      # Сюда будет записываться загружаемая из Яндекс-диска модель
    │   │ 
    │   └── README.md               # Подробное описание модели
    │ 
    ├── ner_service.py              # Flask-app, предоставляющий сервис для вызова моделей по API
    ├── Dockerfile                  # Dockerfile для запуска модуля как сервиса
    ├── requirements.txt            # Локальные зависимости модуля
    └── README.md (вы здесь)        # Описание модуля

## Сборка и запуск сервиса

Предобученные модели можно скачать по ссылке https://disk.yandex.ru/d/7CQPhR2SAu6mxw в виде zip-архива и распаковать в подкаталог `models`, но лучше это не делать вручную, поскольку сервис скачивает нужную модель автоматически при сборке.

Сборка докер-образа с сервисом производится командой
```commandline
docker build -t ivanbondarenko/ner_service:0.1 .
```
Контейнер запускается командой
```commandline
docker run -p 127.0.0.1:8977:8977 ivanbondarenko/interview_ner:0.1
```

## Вызов сервиса

Для использования модуля как отдельного сервиса нужно отправлять
json файл на endpoint `/recognize` с помощью POST-запроса. Например, 
это можно сделать с помощью библиотеки requests и скрипта на python:

```python
import codecs
import requests
import json

filename = "./data/input_example.json"
with codecs.open(filename, mode='r', encoding='utf-8') as fp:
    input_json = json.load(fp)
resp = requests.post(
    'http://localhost:8977/recognize', 
    data=input_json,
    headers={'Content-type': 'application/json', 'Accept': 'text/plain'}
)
```

Протестировать корректную работу собранного и запущенного сервиса можно путём вызова специального тестового скрипта `data/full_test.py`.

#### Входные данные: объект json

Пример входных данных представлен файлом `data\input_example.json`. Предполагается, что на вход сервису поступают данные, прошедшие через сервисы диаризации, распознавания речи, тематической сегментации и восстановления пунктуации.

#### Выходные данные: объект json

Пример выходных данных представлен файлом `data\output_example.json`. По сути, данный сервис ничего не заменяет во входных данных, а только дописывает поле `ners` для каждого тематического сегмента.

## Модели

#### Поддерживаемые модели

Распознаватель именованных сущностей основан на нейросетевой языковой модели BERT, адаптированной для русского языка в рамках проекта DeepPavlov https://huggingface.co/DeepPavlov/rubert-base-cased. Для дообучения этой языковой модели распознаванию именованных сущностей применён авторский алгоритм двухэтапного дообучения:

1. На первом этапе BERT дообучается по принципам сопоставительного обучения (как Сиамская нейронная сеть). В результате этого на последнем скрытом слое модели BERT строится такое семантическое пространство, в котором слова, относящиеся к сущностям одинаковых классов, максимально сближены, а слова, относящиеся к сущностям разных классов, максимально отдалены друг от друга.

2. На втором этапе дообучение модели BERT продолжается уже как дообучение обычного классификатора последовательностей, коим и является NER.

Такой алгоритм получил название **Co**nstrastive **NER**, или **CoNER**. Он позволяет строить более устойчивые модели распознавания, имеющие более высокую обобщающую способность.

#### Обучение моделей

Скрипты для обучения моделей семейства CoNER располагаются в репозитории https://github.com/bond005/runne_contrastive_ner

#### Результаты тестирования


Модель тестировалась в ходе соревнования RuNNE, которое проводилось в рамках очередной конференции ["Диалог-21"](https://www.dialog-21.ru/). Методики формирования датасета для соревнования и тестирования моделей описаны в соответствующем гитхаб-репозитории организаторов https://github.com/dialogue-evaluation/RuNNE. Критерием качества распознавания выступала сбалансированная F-мера, или F1-мера. Результат, достигнутый данной моделью, составил **F1 = 0,74254**, что обеспечило занятие третьего места из десяти (после модели компании Pullenti и модели ВЦ МГУ). Авторская статья с описанием алгоритма **CoNER** и анализом работы моделей, полученных с помощью этого алгоритма, была принята к печати в сборнике трудов вышеупомянутой конференции "Диалог-21" и вскоре будет опубликована.